---
title: "EDS241: FINAL"
author: "Amanda Herbst"
date: '`r format(Sys.time(), "%m/%d/%Y")`'
output: 
  pdf_document:
    toc: false
    number_sections: yes
header-includes:
  \setlength{\parindent}{1em}
  \usepackage{float}
  \renewcommand{\thesubsection}{Question (\alph{subsection})}
--- 

Make sure to read through the setup in markdown. Remember to write out interpretations and report your results in writing/ table/plot forms.

``` {r setup, echo = FALSE, message = FALSE, warning = FALSE, include = FALSE}
#Clean Environment
rm(list=ls())

# Setup your coding process in a way that works for you. 
# Ideally use projects to organize your scripts and outputs. 
# You all probably know more about this than us! 
# For this project, I would create a project with all your data and scripts. 
# I often store data on servers rather than my computer which is why I use the code you see below.

# I set an extension to retrieve data from a particular place (Google Drive/servers etc) 
# and projects to organize my scripts and outputs on my computer/github.

# here I am setting a path to where I stored the data for this assignment
# data_wd <- "/Users/elliottfinn/Library/CloudStorage/GoogleDrive-elliottfinn@ucsb.edu/Shared drives/EDS241/Assignments/Assignment 2" 

# Example of how I use this Data Working Directory:
# data <- read_csv(paste0(data_wd,"/FILE_NAME.csv")) 
# This helps me download/manage my data from different places.

# set default chunk options
knitr::opts_chunk$set(fig.width = 4, fig.height = 3, 
                      echo = TRUE, message = FALSE, warning = FALSE)

# load packages
packages=c(
  # Necessary for Assignment 2
  "Match","plm", "tidyverse", "MatchIt", "RItools", "Hmisc", "lmtest", "estimatr",
  
  # You decide what works for you, these are the packages I use to display results 
  # they may not be the ones you use.
  "gridExtra", "stargazer", "kableExtra", 
  "purrr", "knitr", "broom",
  
  # Some Potentially useful packages from earlier examples
           "stargazer", "here","stringr", "janitor", 
           "cowplot", "ggplot2", "tinytex", "datasets", "tibble") # Used for Mock assignment

for (i in packages) {
  if (require(i,character.only=TRUE)==FALSE) {
    install.packages(i,repos='http://cran.us.r-project.org')
  }
  else {
    require(i,character.only=TRUE)
  }
}

# Disable scientific notation if you want
options(scipen=999)

```

# Part 1: RCTs, treatment ignorability (selection on observables), propensity scores _(15 points total)_

**Setup**

This exercise is inspired by Costello et al. 2008 article in science “Can Catch Shares Prevent Fisheries Collapse”, which we also discussed in class (lecture 5). “Inspired” means that the data final_fisheries_data.csv are synthetically generated to simplify things for our purposes. It contains the variables on 11,135 fisheries (only cross sectional, no time observations): These fisheries were either regulated by an Individual Transferable Quota (ITQ) for all years between 1990 and 2012 or in none of those years. Variables in the dataset include:

**The outcome and treatment variables are:**

\indent COLL_SHARE = share of years a fishery is collapsed between 1990 and 2012 (collapse defined as harvest being more than 10% below maximum recorded harvest).

\indent ITQ = dummy variable indicating ‘treatment’ with an ITQ (equal to 1 if the fishery has been regulated by an ITQ and 0 otherwise). 

**The control variables are:**

\indent MET1, MET2, ….MET6 = Dummy variables indicating to which Marine Ecosystem Type (MET) the fishery belongs to (coral reefs, kelp forests, seagrass meadows, open ocean, deep sea, mangrove forests). This type does not change over the relevant time period and does not depend on human influence.

\indent IND_SR = Index of species richness in 1980 with values between 0 and 100 indicating the biodiversity with respect to species in the fishery. Bounds of 0 and 100 are the lowest and highest observed values of species diversity across all fisheries in 1980, respectively.

\indent COMM_VAL = Commercial value of fisheries in 1980 in million US-$

The basic question of interest is “What is the average treatment effect of implementing an ITQ in the time period from 1990 to 2012 on the share of years with a collapse. It is likely that the probability a fishery is selected for an ITQ depends on the pre-treatment characteristics given. It is also quite likely that the pre-treatment characteristics have an effect on the share of collapse for each fishery, i.e. our outcome variable of interest.

```{r , include=TRUE}
rm(list=ls()) # clean environment

## Load Data
fisheries <- read_csv(here("data", "final_fisheries_data.csv"))

## Prepare Data
# How I setup my coding
# Keep project WD, set extension to get data from google drive 
# data_wd <- "/Users/elliottfinn/Library/CloudStorage/GoogleDrive-elliottfinn@ucsb.edu/Shared drives/EDS241/Exam

# LOAD DATA: final_fisheries_data.csv

```
## Pretreatment Ecosystem Characteristic Comparison, Visual _(3 pts)_
(a) Compare the distributions of pre-treatment ecosystem characteristics (i.e. MET1, MET2, ,,, MET6) between the treated and the control groups by drawing back to back histograms [2 pts]. Write one sentence discussing the (dis)similarity between the two groups [1pt].


```{r , include=TRUE}
## Histograms comparing covariates

histbackback(split(fisheries$MET1, fisheries$ITQ), main = "Distributions of MET1", xlab = c("Control", "Treatment"))
histbackback(split(fisheries$MET2, fisheries$ITQ), main = "Distributions of MET2", xlab = c("Control", "Treatment"))
histbackback(split(fisheries$MET3, fisheries$ITQ), main = "Distributions of MET3", xlab = c("Control", "Treatment"))
histbackback(split(fisheries$MET4, fisheries$ITQ), main = "Distributions of MET4", xlab = c("Control", "Treatment"))
histbackback(split(fisheries$MET5, fisheries$ITQ), main = "Distributions of MET5", xlab = c("Control", "Treatment"))
histbackback(split(fisheries$MET6, fisheries$ITQ), main = "Distributions of MET6", xlab = c("Control", "Treatment"))


## Remember to include histograms in final product

```

## Pretreatment Ecosystem Characteristic Comparison, Mean differences _3 pts)_
(b) Do a test on mean differences between the treated and control groups for the species richness index (IND_SR) and commercial value (COMM_VAL) variables. Interpret the results (estimated difference and significance) [2 pts] and make a conclusion regarding the similarity between the groups [1pt]. 

```{r , include=TRUE}
## Mean Differences (remember to use prop.test or t.test when applicable)

control_continuous <- fisheries %>% 
  select(ITQ, IND_SR, COMM_VAL, )

t_test_results <- data.frame()

# Identifying continuous variables for t-tests
continuous_vars <- names(control_continuous)[-1]
for (var in continuous_vars) {
# Dynamically creating the formula for the t-test
formula <- as.formula(paste(var, "~ ITQ"))
# Performing the t-test
t_test_result <- t.test(formula, data = control_continuous)
# Storing the tidy results of the t-test in the data frame
t_test_result_tidy <- broom::tidy(t_test_result)
t_test_result_tidy$Variable <- var
t_test_results <- rbind(t_test_results, t_test_result_tidy)
}

t_test_results <- t_test_results %>% select(Variable, estimate1, estimate2, p.value)

# Creating a table for output using kable and kableExtra
results_table <- kable(t_test_results, format = "latex",
col.names = c("Variable", "Mean Treated",
"Mean Control", "P-Value"),
caption = "Treated and Untreated Pre-treatment T-Test Results") %>% 
kable_styling(font_size = 7, latex_options = "hold_position")
# Displaying the table
results_table
```

**We can reject the null for both species richness index and commercial value (p < 0.01) therefore there is a significant difference in the means for the treated and untreated groups.**

*check which side is treatment and control*

## Treatment Ignorability _(1 pt)_
(c) Based on your results from (a) and (b), do you see a problem with just comparing the outcome variable means between treated and untreated fisheries? 

**Yes, there is a problem because each marine ecosystem type is not evenly distributed between treatment and control groups, and the mean species richness index and commercial value have significant differences between the averages of the treatment and control groups. We cannot assume treatment ignorability in this case.**

## Propensity Scores _(2 pts)_
(d) Estimate the propensity scores (probability of being treated) using a logit model, assume that all covariates are relevant and should be included in the estimation [0.5 pt]. Draw separate histograms (back to back) of the propensity scores for the treated and the untreated group [0.5 pt]. Comment on the overlap, do you have any concerns? Why/why not? [1]
```{r , include=TRUE}
## Propensity Score Estimates


ps <- glm(ITQ ~ MET1	+ MET2 + MET3	+ MET4	+ MET5 + MET6 + IND_SR + COMM_VAL ,	data=fisheries,	family	= binomial())

# summary table
# Output results with stargazer
stargazer(ps, type="text")

## PS Histogram Unmatched
fisheries$psvalue	<- predict(ps,	type	= "response")
histbackback(split(fisheries$psvalue,	fisheries$ITQ),	main= 
  "Propensity	score	before	matching",	xlab=c("No ITQ",	"ITQ"))
```

**It's concerning that there's so many ITQ especially at higher propensity scores, but there are matches at each bins so that is good***

## ATT with Nearest Neighbor Matching _(3 pts: 2 pt estimate, 1 pt interpretation)_
(e) Use the propensity scores from (c) to estimate the Average Treatment Effect on the Treated (ATT) with a nearest neighbor matching estimator. Interpret the result (just the size of the estimate)
```{r , include=TRUE}
## Nearest Neighbor Matching
## Nearest-neighbor Matching
m.nn	<- matchit(ITQ	~ MET1	+ MET2 + MET3	+ MET4	+ MET5 + MET6 + IND_SR + COMM_VAL,	data=fisheries,	method= "nearest",	ratio	= 1)
summary(m.nn)
match.data	= match.data(m.nn)
## Estimate ATT
sumdiff_data<-match.data%>%
  group_by(subclass)%>%
  mutate(diff=COLL_SHARE[ITQ==1]-COLL_SHARE[ITQ==0])

sumdiff <- sum(sumdiff_data$diff)/2
ATT_m_nn = 1/sum(fisheries$ITQ) * sumdiff
ATT_m_nn
```

**What is the average treatment effect on the treated fisheries of implementing an ITQ in the time period from 1990 to 2012 is a decrease in the share of years with a collapse by 6%.**

## ATE with WLS _(3 pts: 1 pt estimate, 1 pt interpretation)_
(f) Estimate the Average Treatment Effect (ATE) using the weighted least squares on the full sample. Interpret the estimated size and conclude if it is significantly different from zero from a statistical perspective.
```{r , include=TRUE}
## WLS Matching
## Weighted least Squares (WLS) estimator Preparation
fisheries$wgt = (fisheries$ITQ/fisheries$psvalue + 
              (1-fisheries$ITQ)/(1-fisheries$psvalue))

## Estimate ATE
## Weighted least Squares (WLS) Estimates
reg_wls	<-lm(COLL_SHARE	~ ITQ +	MET1	+ MET2 + MET3	+ MET4	+ MET5 + MET6 + IND_SR + COMM_VAL,
             data = fisheries, weights = wgt)
## Present Results
stargazer(reg_wls, type = "text")
```

**The estimated average treatment effect, calculated with a weighted least squares regression, is a 7.7 percent (percentage point?) decrease in share of years with a collapse. We can reject the null hypothesis (p < 0.01) so the this estimate is significantly different**

# Part 2 Difference in Difference Estimation _(10 points total + 3pts extra credit)_

\indent Here we return for a final time to the dataset from Gertler, Martinez, and Rubio-Codina (2012) and use a different way of estimating the effect of the Mexican conditional cash transfer on the value of animal holdings of recipients. We’ll use the panel data from assignment 2, where you have both the pre-program and post-program observations. See Template for dataset preparation instructions.

\indent **Data Preparation**

\indent *Note: You will need to install the packages plm and dplyr (included in template preamble). Again, you can find a description of the variables at the bottom of PDF and HERE.

Prepare Data: Load the new data (progresa_pre_1997.csv) and the follow-up data (progresa_post_1999.csv) into R. Note that we created a time denoting variable (with the same name, 'year') in BOTH datasets. Again, you will create a panel dataset by appending the data (i.e. binding the dataset row-wise together creating a single dataset). We want to examine the same outcome variable as before, value of family animal holdings (vani). You will use the full dataset for each estimate. NOTE: you should not change any NAs from the TREATED column in your analysis, as we expect that spillover was likely in this program. NAs will be excluded from your calculations/estimations.

```{r , include=TRUE, echo=FALSE}
rm(list=ls()) # clean environment

## Load Data
progresa_pre_1997 <- read_csv(here::here("data", "progresa_pre_1997.csv"))
progresa_post_1999 <- read_csv(here::here("data", "progresa_post_1999.csv"))

## Append post to pre dataset 
progresa <- rbind(progresa_pre_1997, progresa_post_1999)
#(note, you can keep NAs in the data- they'll be excluded from any estimates etc)

rm(progresa_pre_1997, progresa_post_1999) # clean unused data

```
## DiD Estimator, ATE _(5 pts: 3 pts estimate, 2 pts interpretation)_
(a) Calculate the DiD estimator of the treatment effect (ATE) of the program on the value of animal holdings (vani)  “manually” i.e. based on group mean values without running a regression. Report and interpret the result (Note: no significance test or standard errors is possible, so you do not need to report these values).
```{r, include=TRUE}

## Estimate ATE with DiD estimator manually. 
# You will need to calculate various means to get this estimate
mean_control_97 <- progresa %>% 
  filter(year == 1997 & treatment == 0) %>% 
  summarise(mean = mean(vani, na.rm = TRUE))

mean_control_99 <- progresa %>% 
  filter(year == 1999 & treatment == 0) %>% 
  summarise(mean = mean(vani, na.rm = TRUE))

mean_treat_97 <- progresa %>% 
  filter(year == 1997 & treatment == 1) %>% 
  summarise(mean = mean(vani, na.rm = TRUE))

mean_treat_99 <- progresa %>% 
  filter(year == 1999 & treatment == 1) %>% 
  summarise(mean = mean(vani, na.rm = TRUE))
              
## Compute the Difference-in-Differences

progresa %>% 
  group_by(year, treatment) %>% 
  summarise(mean = mean(vani))

did <- (mean_treat_99 - mean_treat_97) - (mean_control_99 - mean_control_97)
did
```
**The impact of the cash transfer increased the average value of animal holdings by 321**


## Difference in Difference using OLS _(5 pts)_
(b) Now set up an OLS-regression using group mean values to estimate the same ATE. Interpret the estimated treatment effect [3 pts]. Also interpret the coefficients on the time dummy and the group dummy variable (see interpretation done in class in lecture 9) [2 pts]. 

\indent **Hints:** You will need to create a new dataframe with a variety of dummy variables to do this. The R example provided with the DiD module (and/or the excel file) should help.

```{r, include=TRUE}
## Create a new data frame for OLS regression
progresa_did <- progresa %>% 
  mutate(post_treat = case_when(
    year == 1997 ~ 0,
    year == 1999 ~ 1
  )) %>% 
  mutate(time_x_treated = post_treat*treatment) %>% 
  group_by(post_treat, treatment, time_x_treated) %>% 
  summarise(mean_vani = mean(vani))

## Run the OLS regression w/dummies
# Run the regression with group means
model1 <- lm(mean_vani ~ treatment + post_treat + time_x_treated, 
            data = progresa_did)

## Report OLS Model results Print the summary of the OLS model
# Get summary of the model
summary(model1)

```

**delta (treated coefficient) = -271.3 mean difference in animal holdings value for households that received the cash transfer and households that didn't, pre treatment)**
**alpha (post_treat coefficient)= -1170 mean change in vanimal holdings value for households that didn't receive the cash transfer between pretreatment time and post treatment time)**
**b3 (interaction)= 321.5 This is our coefficient of interest. The effect of the cash transfer on value of animal holdings**
**Giving households a conditional cash transfer caused an increase in the value of animal holdings, on average, by $321 per household that received the cash transfer.**

# Extra Credit: ATE with OLS using full dataset _(3 pts: 2 pts estimate, 1 pt interpretation)_
(c) Estimate the ATE with an OLS-regression based on the original units as observations (i.e. not with group mean values, you will need to use the entire dataset). Even though the specification is the same as in the regression with the group mean values above, you’ll need to create new indicator variables for the treatment group and the post treatment time period as well as their interaction term. Verify that you get the same result as above. Now report also on the precision of the estimation and test whether the estimated coefficient is different from zero. 

```{r, include=TRUE}
## Create the dummy variables (you'll need 3)


## OLS regression


# Present Regressions in Table


```














